{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias and fairness in machine learning\n",
    "\n",
    "In this notebook, we'll take a hands on approach to the study of bias and fairness in machine learning, focusing primarily on word embeddings. Word embeddings are (comparatively) low-dimensional vector representations of words that attempt to capture semantics (or meaning). Conceptually, word embeddings are motivated by the observation that the meaning of a word is characterized by \"the company that it keeps\" (i.e., that we can learn about the meaning of words by looking at the contexts in which they appear). In recent years, advances in computation (e.g., GPUs) and machine learning have made it possible to train embeddings on large-scale text data, thereby making embeddings more valuable for commercial, scientific, and other applications. \n",
    "\n",
    "Like all machine learning algorithms, word embeddings depend on training data, specifically text, which is of course generated by human beings. Consequently, there is growing concern that word embeddings may encode human biases (e.g., streotypes about particular groups). Our goal in this session will be to see if we can identify such biases in several widely used, pre-trained word embedding models.\n",
    "\n",
    "Without further ado, let's get started. \n",
    "\n",
    "# Roadmap\n",
    "  * Preliminaries\n",
    "  * Word embeddings\n",
    "    * Similarities\n",
    "    * Analogies\n",
    "  * Language models\n",
    "    * Next word prediction\n",
    "    * Masked word prediction\n",
    "  * Exercises\n",
    "\n",
    "# Preliminaries\n",
    "\n",
    "Let's start by loading some packages. We'll use gensim to download some pre-trained word embeddings and to run operations on the vectors. We'll use pandas for wrangling some data, numpy for some handy array operations, and itertools to help with some pairwise distances calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npip install pandas\\npip install gensim\\npip install numpy\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the following commands to install the needed packages\n",
    "\"\"\"\n",
    "pip install pandas\n",
    "pip install gensim\n",
    "pip install numpy\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some packages\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load our model. This is the set of pre-trained embeddings (i.e., we get a vector for each word). Our package, gensim, comes with some built in embeddings, and to keep things simple, we'll use those. To get us started, we'll load `glove-wiki-gigaword-50`, which are trained on the text of Wikipedia. The 100 means that our vectors are in $\\mathbb{R}^{50}$; you don't need to worry about that now, but we'll come back to the dimensions later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and load the model\n",
    "embeddings = gensim.downloader.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get more information on our model like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_records': 400000,\n",
       " 'file_size': 69182535,\n",
       " 'base_dataset': 'Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)',\n",
       " 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-50/__init__.py',\n",
       " 'license': 'http://opendatacommons.org/licenses/pddl/',\n",
       " 'parameters': {'dimension': 50},\n",
       " 'description': 'Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).',\n",
       " 'preprocessing': 'Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-50.txt`.',\n",
       " 'read_more': ['https://nlp.stanford.edu/projects/glove/',\n",
       "  'https://nlp.stanford.edu/pubs/glove.pdf'],\n",
       " 'checksum': 'c289bc5d7f2f02c6dc9f2f9b67641813',\n",
       " 'file_name': 'glove-wiki-gigaword-50.gz',\n",
       " 'parts': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.info(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings\n",
    "\n",
    "Now that we've loaded our word embeddings, we're ready to start running some analyses. Recall that we're just working with a bunch of vectors. Let's check out the vectors for the word `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13175 , -0.25517 , -0.067915,  0.26193 , -0.26155 ,  0.23569 ,\n",
       "        0.13077 , -0.011801,  1.7659  ,  0.20781 ,  0.26198 , -0.16428 ,\n",
       "       -0.84642 ,  0.020094,  0.070176,  0.39778 ,  0.15278 , -0.20213 ,\n",
       "       -1.6184  , -0.54327 , -0.17856 ,  0.53894 ,  0.49868 , -0.10171 ,\n",
       "        0.66265 , -1.7051  ,  0.057193, -0.32405 , -0.66835 ,  0.26654 ,\n",
       "        2.842   ,  0.26844 , -0.59537 , -0.5004  ,  1.5199  ,  0.039641,\n",
       "        1.6659  ,  0.99758 , -0.5597  , -0.70493 , -0.0309  , -0.28302 ,\n",
       "       -0.13564 ,  0.6429  ,  0.41491 ,  1.2362  ,  0.76587 ,  0.97798 ,\n",
       "        0.58507 , -0.30176 ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most similar words\n",
    "\n",
    "What's neat is that since we're working with vectors, we can start to do things like look for words that are similar (by finding nearby vectors). Here's how we would to that in gensim. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dog', 0.9218006134033203),\n",
       " ('rabbit', 0.8487821817398071),\n",
       " ('monkey', 0.8041081428527832),\n",
       " ('rat', 0.7891963720321655),\n",
       " ('cats', 0.7865270376205444),\n",
       " ('snake', 0.7798910737037659),\n",
       " ('dogs', 0.7795815467834473),\n",
       " ('pet', 0.7792249917984009),\n",
       " ('mouse', 0.7731667757034302),\n",
       " ('bite', 0.7728800177574158)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cat', 0.9218006134033203),\n",
       " ('dogs', 0.8513158559799194),\n",
       " ('horse', 0.7907583117485046),\n",
       " ('puppy', 0.7754921317100525),\n",
       " ('pet', 0.7724707722663879),\n",
       " ('rabbit', 0.7720814347267151),\n",
       " ('pig', 0.7490062117576599),\n",
       " ('snake', 0.7399188876152039),\n",
       " ('baby', 0.7395570874214172),\n",
       " ('bite', 0.738793671131134)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.most_similar(\"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('barack', 0.9674172401428223),\n",
       " ('bush', 0.9642480611801147),\n",
       " ('clinton', 0.9606045484542847),\n",
       " ('mccain', 0.9122934937477112),\n",
       " ('dole', 0.8878742456436157),\n",
       " ('gore', 0.884803831577301),\n",
       " ('hillary', 0.8776552677154541),\n",
       " ('rodham', 0.8401790857315063),\n",
       " ('kerry', 0.8261429071426392),\n",
       " ('biden', 0.8095825910568237)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.most_similar(\"obama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already, you can imagine how we might begin probing for potential biases. For example, we might look at the most similar words for different occupations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('physician', 0.8497322797775269),\n",
       " ('cardiologist', 0.7978282570838928),\n",
       " ('dentist', 0.795362114906311),\n",
       " ('orthopedic', 0.7693870663642883),\n",
       " ('neurologist', 0.7677544355392456),\n",
       " ('psychiatrist', 0.7599009871482849),\n",
       " ('surgeons', 0.7580606937408447),\n",
       " ('oncologist', 0.7523747086524963),\n",
       " ('pediatric', 0.7517416477203369),\n",
       " ('doctor', 0.7479072213172913),\n",
       " ('neurosurgeon', 0.7459368705749512),\n",
       " ('ophthalmologist', 0.7451258301734924),\n",
       " ('pathologist', 0.7448002696037292),\n",
       " ('nurse', 0.7376463413238525),\n",
       " ('orthopaedic', 0.737062931060791),\n",
       " ('internist', 0.7313891649246216),\n",
       " ('pediatrician', 0.7174053192138672),\n",
       " ('anesthesiologist', 0.7062750458717346),\n",
       " ('surgery', 0.7021859884262085),\n",
       " ('urologist', 0.6995974183082581)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.most_similar(\"surgeon\", topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('doctor', 0.7977497577667236),\n",
       " ('nurses', 0.7752917408943176),\n",
       " ('dentist', 0.7731257081031799),\n",
       " ('pregnant', 0.7462233901023865),\n",
       " ('pediatrician', 0.7452079653739929),\n",
       " ('therapist', 0.7396323084831238),\n",
       " ('surgeon', 0.7376462817192078),\n",
       " ('nursing', 0.7353047728538513),\n",
       " ('child', 0.7341340184211731),\n",
       " ('counselor', 0.7322410345077515),\n",
       " ('teacher', 0.7242345213890076),\n",
       " ('patient', 0.7242098450660706),\n",
       " ('psychiatrist', 0.7219806909561157),\n",
       " ('physician', 0.7205138206481934),\n",
       " ('parents', 0.7181951403617859),\n",
       " ('mother', 0.7177230715751648),\n",
       " ('woman', 0.7155020236968994),\n",
       " ('hospital', 0.7076544761657715),\n",
       " ('paramedic', 0.7050016522407532),\n",
       " ('anesthetist', 0.700419008731842)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.most_similar(\"nurse\", topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we see more clearly gendered words associated with nurse. Take a few minutes to enter alternative occupations in the code above. Do you find any interesting differences?\n",
    "\n",
    "## Distances between words\n",
    "\n",
    "We can also get more explicit in our queries. Rather than limiting our attention to the most similar words, let's go ahead and narrow in on the relationship among particular word pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5610992014408112"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.distance(\"surgeon\", \"he\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5496048629283905"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.distance(\"surgeon\", \"she\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5194914042949677"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.distance(\"nurse\", \"he\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3543033003807068"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.distance(\"nurse\", \"she\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distances between \"he\" and \"she\" and doctor are quite similar. But there is quite a large gap between the corresponding distances between \"he\" and \"she\" and \"nurse\". As we did before, take a few minutes to explore distances among pairs of words that you think might be a useful diagnostic for biases. To help you explore a broader set of word pairs, here is a little function that will return a matrix of pairwise distances, given a list of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matrix(embeddings, words):\n",
    "  mtx = np.array([embeddings.distance(a, b) for a,b in itertools.product(words, words)]).reshape(len(words), len(words))\n",
    "  return pd.DataFrame(mtx, index=words, columns=words).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the function like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>he</th>\n",
       "      <th>she</th>\n",
       "      <th>nurse</th>\n",
       "      <th>ceo</th>\n",
       "      <th>engineer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurse</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ceo</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engineer</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            he   she  nurse   ceo  engineer\n",
       "he        0.00  0.11   0.52  0.61      0.51\n",
       "she       0.11  0.00   0.35  0.69      0.59\n",
       "nurse     0.52  0.35   0.00  0.80      0.52\n",
       "ceo       0.61  0.69   0.80  0.00      0.57\n",
       "engineer  0.51  0.59   0.52  0.57      0.00"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_matrix(embeddings=embeddings, words=[\"he\", \"she\", \"nurse\", \"ceo\", \"engineer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector magic\n",
    "\n",
    "If you've read anything on word embeddings, you've probably seen some examples of analogies, the most famous probably being $queen = king - man + woman$. Remember that we're just working with vectors, so we can use vector arithmetic. Let's see if we can replicate the famous king/queen example. We'll start by looking at words similar to \"king\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('physician', 0.8497322797775269),\n",
       " ('cardiologist', 0.7978282570838928),\n",
       " ('dentist', 0.795362114906311),\n",
       " ('orthopedic', 0.7693870663642883),\n",
       " ('neurologist', 0.7677544355392456),\n",
       " ('psychiatrist', 0.7599009871482849),\n",
       " ('surgeons', 0.7580606937408447),\n",
       " ('oncologist', 0.7523747086524963),\n",
       " ('pediatric', 0.7517416477203369),\n",
       " ('doctor', 0.7479072213172913),\n",
       " ('neurosurgeon', 0.7459368705749512),\n",
       " ('ophthalmologist', 0.7451258301734924),\n",
       " ('pathologist', 0.7448002696037292),\n",
       " ('nurse', 0.7376463413238525),\n",
       " ('orthopaedic', 0.737062931060791),\n",
       " ('internist', 0.7313891649246216),\n",
       " ('pediatrician', 0.7174053192138672),\n",
       " ('anesthesiologist', 0.7062750458717346),\n",
       " ('surgery', 0.7021859884262085),\n",
       " ('urologist', 0.6995974183082581)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.most_similar(\"surgeon\", topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll do a little arithmetic, using some options built into gensim's `most_similar` method. So we're adding the vectors for \"king\" and \"woman\" and subtracting the vector for \"man\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.8523604273796082),\n",
       " ('throne', 0.7664334177970886),\n",
       " ('prince', 0.759214460849762),\n",
       " ('daughter', 0.7473882436752319),\n",
       " ('elizabeth', 0.7460219860076904),\n",
       " ('princess', 0.7424570322036743),\n",
       " ('kingdom', 0.7337412238121033),\n",
       " ('monarch', 0.7214491367340088),\n",
       " ('eldest', 0.7184861898422241),\n",
       " ('widow', 0.7099431157112122),\n",
       " ('son', 0.7081551551818848),\n",
       " ('father', 0.7072948217391968),\n",
       " ('mother', 0.6993737816810608),\n",
       " ('emperor', 0.6989730596542358),\n",
       " ('grandson', 0.6946032047271729),\n",
       " ('wife', 0.6925390362739563),\n",
       " ('consort', 0.6895833611488342),\n",
       " ('family', 0.6888480186462402),\n",
       " ('cousin', 0.6867153644561768),\n",
       " ('marriage', 0.6804890632629395)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.most_similar(positive=[\"woman\", \"king\"], negative=[\"man\"], topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty impressive! But how can we use this to study bias and fairness in machine learning. Well, we might go back to our example with gendered occupations. What's your guess on what we'll get when we run $doctor - man + woman$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nurse', 0.840464174747467),\n",
       " ('child', 0.7663259506225586),\n",
       " ('pregnant', 0.7570130228996277),\n",
       " ('mother', 0.7517457604408264),\n",
       " ('patient', 0.751666247844696),\n",
       " ('physician', 0.7507280707359314),\n",
       " ('dentist', 0.7360344529151917),\n",
       " ('therapist', 0.7342537045478821),\n",
       " ('parents', 0.7286345958709717),\n",
       " ('surgeon', 0.7165213823318481),\n",
       " ('teacher', 0.7138692736625671),\n",
       " ('doctors', 0.7117718458175659),\n",
       " ('birth', 0.7071055769920349),\n",
       " ('psychiatrist', 0.6999903321266174),\n",
       " ('girl', 0.6961426138877869),\n",
       " ('she', 0.6924219727516174),\n",
       " ('her', 0.6886029243469238),\n",
       " ('daughter', 0.6861442923545837),\n",
       " ('pediatrician', 0.6856350302696228),\n",
       " ('toddler', 0.6853212118148804)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.most_similar(positive=[\"woman\", \"doctor\"], negative=[\"man\"], topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we try to probe more directly for what our word vectors think about gender roles? What might we get when we run $role - man + woman$ and $role - woman + man$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('as', 0.783684492111206),\n",
       " ('acting', 0.7572517991065979),\n",
       " ('future', 0.7556937336921692),\n",
       " ('roles', 0.7423116564750671),\n",
       " ('action', 0.7377783060073853),\n",
       " ('supporting', 0.7366944551467896),\n",
       " ('both', 0.7362772226333618),\n",
       " ('character', 0.7349316477775574),\n",
       " ('success', 0.7314870953559875),\n",
       " (\"'s\", 0.7283881902694702),\n",
       " ('well', 0.7250850796699524),\n",
       " ('this', 0.7232421040534973),\n",
       " ('powers', 0.7225099205970764),\n",
       " ('leadership', 0.7218052744865417),\n",
       " ('own', 0.7188370823860168),\n",
       " ('responsible', 0.7167803049087524),\n",
       " ('credited', 0.7158978581428528),\n",
       " ('also', 0.7135252356529236),\n",
       " ('whose', 0.7121561765670776),\n",
       " ('major', 0.7117612361907959)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.most_similar(positive=[\"man\", \"role\"], negative=[\"woman\"], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('roles', 0.7808736562728882),\n",
       " ('relationship', 0.7652266621589661),\n",
       " ('acting', 0.7191237807273865),\n",
       " ('child', 0.7111478447914124),\n",
       " ('focuses', 0.6989119648933411),\n",
       " ('supporting', 0.697880208492279),\n",
       " ('her', 0.6972039341926575),\n",
       " ('engagement', 0.6958260536193848),\n",
       " ('marriage', 0.6946836113929749),\n",
       " ('life', 0.6913840174674988),\n",
       " ('’s', 0.6887852549552917),\n",
       " ('relations', 0.6872742176055908),\n",
       " ('she', 0.6801809668540955),\n",
       " ('recognition', 0.6747872233390808),\n",
       " ('character', 0.6741839051246643),\n",
       " ('focus', 0.6686821579933167),\n",
       " ('herself', 0.6652383208274841),\n",
       " ('status', 0.6644878387451172),\n",
       " ('collaboration', 0.6629896759986877),\n",
       " ('part', 0.6629751324653625)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.most_similar(positive=[\"woman\", \"role\"], negative=[\"man\"], topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results contain some pretty stereotypical gender characterizations, even on a quick glance, with the \"man\" word list including things like \"futures\", \"success\", \"powers\" and \"leadership\" and the \"woman\" list including things like \"relationship\", \"child\", \"engagement\", and \"marriage\".\n",
    "\n",
    "Take a few minutes and adapt the code above to run some more analogies. Can you find any additional evidence of biases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language models\n",
    "\n",
    "There are a lot of interesting things we can do with word embeddings. As impressive as they are, though, they're just the tip of the iceberg in terms of what can (and is) being done with modern natural language processing. In this next section of our notebook, we'll narrow in on two particular examples, (1) next word prediction and (2) masked word prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next word prediction\n",
    "\n",
    "We're all familiar with next word prediction. This is what's happening behind the scenes any time we run a Google search and see the automatic query suggestions. It's not too tricky to do next word prediction in Python, but it's a bit more involved than fiddling around with word embeddings, and since this isn't a methodological class, writing our own code will be a bit too much. Fortunately, there a lot of great online tools that will let us play around with state of the art models. \n",
    "\n",
    "Here is an online demonstration using the AllenNLP natural language processing platform. Under the hood, the demonstration uses GPT-2, which is a state of the art language model. \n",
    "\n",
    "[AllenNLP Next Token Demo](https://demo.allennlp.org/next-token-lm?text=AllenNLP%20is%20)\n",
    "\n",
    "Take a few minutes to play around with the demonstration. Can you find any evidence of biases? How might you adapt some of the occupational examples we tried out above to the next work prediction context? Can you think of any other ways we might probe for biases?\n",
    "\n",
    "### Bonus\n",
    "If you want to check next word prediction for a much broader set of state of the art models (in a Google docs type environment), here is your chance.\n",
    "\n",
    "[Huggingface Write With Transformer](https://transformer.huggingface.co/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masked word prediction\n",
    "\n",
    "Masked word prediction is pretty similar to next word prediction, except here, we're trying to predict a hidden word typically in the middle of some other text content. As with next word prediction, actually implementing masked word prediction is a bit beyond the scope of this class. But again, we're lucky that there are a lot of demos available online, including one from AllenNLP. \n",
    "\n",
    "[AllenNLP Masked Word Demo](https://demo.allennlp.org/masked-lm?text=The%20doctor%20ran%20to%20the%20emergency%20room%20to%20see%20%5BMASK%5D%20patient)\n",
    "\n",
    "Once again, take a few minutes to fiddle with the demonstration. Can you find any evidence of biases? What kinds of tests might you do? Hint: the default example given by the AllenNLP creators is already quite revealing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "  * The examples above were all based on a single set of word vectors, trained on Twitter data. In addition, the word vectors we used were fairly low dimensional. Repeat the exercises above, but using a different model. \n",
    "    * How much does the model size (dimensionality) make a difference?\n",
    "    * Do you notice any differences when you try models trained on a different corpus (e.g., Wikipedia, Twitter)?\n",
    "  * To more systematically uncover biases in word embeddings, previous research has attempted to adapt the Implicit Association Test (IAT), which is a test designed to unearth unconscious biases in humans. While we don't have time right now to do a systematic analysis, the various IATs that have been developed over the years can serve as some inspiration for additional queries on our word vectors. Take a look at the IAT website, [here](https://implicit.harvard.edu/implicit/selectatest.html). Pick a test, and look at the word pairs you're given. Run some distance and/or analogy queries for the different word pairs you're given. Can you find any evidence of biases?\n",
    "\n",
    "# Loading a different model\n",
    "\n",
    "To load a different model, just restart the notebook, and change the string `glove-wiki-gigaword-50` in the line of code below (but at the top of the notebook) to the model you'd like to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`embeddings = gensim.downloader.load(\"glove-wiki-gigaword-50\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following models are available in gensim; `wiki` and `twitter` indicate the source of the training data are Wikipedia or Twitter, respectively. The number indicates the dimensionality of the vectors. \n",
    "  * `glove-wiki-gigaword-50`\n",
    "  * `glove-wiki-gigaword-100`\n",
    "  * `glove-wiki-gigaword-200`\n",
    "  * `glove-wiki-gigaword-300`\n",
    "  * `glove-twitter-25`\n",
    "  * `glove-twitter-50`\n",
    "  * `glove-twitter-100`\n",
    "  * `glove-twitter-200`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
